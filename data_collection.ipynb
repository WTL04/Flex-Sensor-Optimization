{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing Different ML Models on Flex Sensor Bend Data #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 1)) (2.2.5)\n",
            "Requirement already satisfied: pandas in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 3)) (3.10.3)\n",
            "Requirement already satisfied: scikit-learn in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: xgboost in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: torch in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 6)) (2.7.0)\n",
            "Requirement already satisfied: seaborn in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 7)) (0.13.2)\n",
            "Requirement already satisfied: statsmodels in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 8)) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from pandas->-r req.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from pandas->-r req.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from pandas->-r req.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from scikit-learn->-r req.txt (line 4)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from scikit-learn->-r req.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from scikit-learn->-r req.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from xgboost->-r req.txt (line 5)) (2.26.2)\n",
            "Requirement already satisfied: filelock in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (4.13.2)\n",
            "Requirement already satisfied: setuptools in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (80.4.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from statsmodels->-r req.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->-r req.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->-r req.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from jinja2->torch->-r req.txt (line 6)) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r req.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m This environment is externally managed\n",
            "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
            "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
            "\u001b[31m   \u001b[0m install.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
            "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
            "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
            "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
            "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
            "\u001b[31m   \u001b[0m installed via pacman.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
            "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model training & pipelines\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RationalQuadratic, WhiteKernel, ConstantKernel as C\n",
        "# from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collection ##\n",
        "\n",
        "In this notebook, the data I have here is from Wally's work, Besufekad's, and some simulated data I made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Angle (degrees)  Resistance (kÎ©)\n",
            "0              165             22.07\n",
            "1              116             17.14\n",
            "2              117             17.21\n",
            "3              180             20.36\n",
            "4              180             20.00\n",
            "Missing values:\n",
            " Angle (degrees)     0\n",
            "Resistance (kÎ©)    0\n",
            "dtype: int64\n",
            "Data types:\n",
            " Angle (degrees)       int64\n",
            "Resistance (kÎ©)    float64\n",
            "dtype: object\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of      Angle (degrees)  Resistance (kÎ©)\n",
              "0                165             22.07\n",
              "1                116             17.14\n",
              "2                117             17.21\n",
              "3                180             20.36\n",
              "4                180             20.00\n",
              "..               ...               ...\n",
              "812               71             13.09\n",
              "813              106             19.57\n",
              "814               91             14.77\n",
              "815               73             12.48\n",
              "816              102             19.83\n",
              "\n",
              "[817 rows x 2 columns]>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the datasets\n",
        "file1 = \"datasets/flex_sensor_data.csv\"\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "df = pd.concat([df1], ignore_index=True)  # `ignore_index=True` resets the index\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle and reset index\n",
        "\n",
        "# Display first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values:\\n\", df.isnull().sum())\n",
        "\n",
        "# Check data types\n",
        "print(\"Data types:\\n\", df.dtypes)\n",
        "\n",
        "df.describe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Prep ##\n",
        "\n",
        "We will be testing to see if the model can accurately predict the bending angle of the sensor based on resistance readings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define features (X) and target variable (y)\n",
        "X = df.drop(columns=['Angle (degrees)'])  # Replace 'TargetColumn' with the actual column name\n",
        "y = df['Angle (degrees)']\n",
        "\n",
        "# Split data into training and test sets (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional, based on sensor value range)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the Models ##\n",
        "\n",
        "The models that will be tested in this notebook:\n",
        "* Baseline models:\n",
        "    * Random Forest\n",
        "    * Linear Regression\n",
        "    * Polynomial Regression\n",
        "* Advance models:\n",
        "    * XGBoost Regression\n",
        "    * Gaussian Process Regression\n",
        "    * Model Generalization (combining all models together)\n",
        "\n",
        "## Evaluation ##\n",
        "\n",
        "Metrics to be used:\n",
        "* Mean squared error (MSE) - measures error magnitude\n",
        "* R**2 - evaluates model accuracy\n",
        "* Prediction curve evaluation - plots actual vs. predicted bending angles to observe trends"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest Model ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        }
      ],
      "source": [
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],  # Number of trees\n",
        "    'max_depth': [10, 20, 30, None],  # Tree depth\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples to split\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum samples in a leaf node\n",
        "    'max_features': ['sqrt', 'log2'],  # Number of features per split\n",
        "    'bootstrap': [True, False]  # Bootstrapping\n",
        "}\n",
        "\n",
        "# Initialize Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define parameter space for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 500, 700],  # More options for better tuning\n",
        "    'max_depth': [10, 20, 30, 50, 60, None],  # None allows fully grown trees\n",
        "    'min_samples_split': [2 ,3, 4, 5, 6],  # More splits to avoid overfitting\n",
        "    'min_samples_leaf': [1, 2, 4 , 5, 6],  # Controls complexity\n",
        "    'max_features': ['sqrt', 'log2', None],  # Feature selection strategies\n",
        "    'bootstrap': [True, False]  # Bootstrapping options\n",
        "}\n",
        "\n",
        "# Randomized Search with Cross Validation (5-fold)\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf_model, param_distributions=param_dist,\n",
        "    n_iter=20,  # Randomly test 20 different combinations\n",
        "    scoring='r2', cv=5, n_jobs=-1, verbose=2, random_state=42\n",
        ")\n",
        "\n",
        "# Fit Randomized Search to training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"\\nBest Hyperparameters:\", random_search.best_params_)\n",
        "\n",
        "# Train Random Forest with best parameters\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2 = r2_score(y_test, y_pred_rf)\n",
        "n, p = X_test.shape\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "print(\"\\n🌲 Random Forest Performance:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
        "\n",
        "# Cross-Validation\n",
        "cv_scores = cross_val_score(best_rf_model, X, y, cv=5, scoring='r2')\n",
        "cv_preds = cross_val_predict(best_rf_model, X, y, cv=5)\n",
        "cv_rmse = np.sqrt(mean_squared_error(y, cv_preds))\n",
        "cv_mae = mean_absolute_error(y, cv_preds)\n",
        "cv_r2 = r2_score(y, cv_preds)\n",
        "\n",
        "print(f\"\\n🔁 Cross-Validation (5-Fold):\")\n",
        "print(f\"R² Scores: {cv_scores}\")\n",
        "print(f\"Average R²: {cv_scores.mean():.4f}\")\n",
        "print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
        "print(f\"CV MAE: {cv_mae:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost Training Model ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize XGBoost Regressor\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 300, 500, 700],  # Number of boosting rounds\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # How much each tree contributes\n",
        "    'max_depth': [3, 5, 7, 10],  # Complexity control\n",
        "    'min_child_weight': [1, 3, 5],  # Minimum weight needed for a new node split\n",
        "    'gamma': [0, 0.1, 0.3, 0.5],  # Regularization parameter\n",
        "    'colsample_bytree': [0.5, 0.7, 1],  # Percentage of features used per tree\n",
        "    'subsample': [0.6, 0.8, 1]  # Fraction of samples per tree\n",
        "}\n",
        "\n",
        "# Randomized Search with Cross Validation (5-fold)\n",
        "random_search_xgb = RandomizedSearchCV(\n",
        "    estimator=xgb_model, param_distributions=param_dist,\n",
        "    n_iter=20,  # Randomly test 20 different combinations\n",
        "    scoring='r2', cv=5, n_jobs=-1, verbose=2, random_state=42\n",
        ")\n",
        "\n",
        "# Fit Randomized Search to training data\n",
        "random_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"\\nBest Hyperparameters:\", random_search_xgb.best_params_)\n",
        "\n",
        "# Train XGBoost with best parameters\n",
        "best_xgb_model = random_search_xgb.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred_xgb)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2 = r2_score(y_test, y_pred_xgb)\n",
        "n, p = X_test.shape\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "print(\"\\n🌲 XGBoost Performance:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
        "\n",
        "# Cross-Validation\n",
        "cv_scores = cross_val_score(best_xgb_model, X, y, cv=5, scoring='r2')\n",
        "cv_preds = cross_val_predict(best_xgb_model, X, y, cv=5)\n",
        "cv_rmse = np.sqrt(mean_squared_error(y, cv_preds))\n",
        "cv_mae = mean_absolute_error(y, cv_preds)\n",
        "cv_r2 = r2_score(y, cv_preds)\n",
        "\n",
        "print(f\"\\n🔁 Cross-Validation (5-Fold):\")\n",
        "print(f\"R² Scores: {cv_scores}\")\n",
        "print(f\"Average R²: {cv_scores.mean():.4f}\")\n",
        "print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
        "print(f\"CV MAE: {cv_mae:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Regression Model ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "mse = mean_squared_error(y_test, y_pred_lr)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_lr)\n",
        "r2 = r2_score(y_test, y_pred_lr)\n",
        "n, p = X_test.shape\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "print(\"\\n📉 Linear Regression Performance:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
        "\n",
        "# Coefficients\n",
        "coef_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': lr_model.coef_})\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(coef_df)\n",
        "print(f\"Intercept: {lr_model.intercept_:.4f}\")\n",
        "\n",
        "# Cross-Validation\n",
        "cv_scores = cross_val_score(lr_model, X, y, cv=5, scoring='r2')\n",
        "cv_preds = cross_val_predict(lr_model, X, y, cv=5)\n",
        "cv_rmse = np.sqrt(mean_squared_error(y, cv_preds))\n",
        "cv_mae = mean_absolute_error(y, cv_preds)\n",
        "cv_r2 = r2_score(y, cv_preds)\n",
        "\n",
        "print(f\"\\n🔁 Cross-Validation (5-Fold):\")\n",
        "print(f\"R² Scores: {cv_scores}\")\n",
        "print(f\"Average R²: {cv_scores.mean():.4f}\")\n",
        "print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
        "print(f\"CV MAE: {cv_mae:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Polynomial Regression Model ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train model\n",
        "degree = 4\n",
        "poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "poly_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_poly = poly_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred_poly)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_poly)\n",
        "r2 = r2_score(y_test, y_pred_poly)\n",
        "n, p = X_test.shape\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "# Output results\n",
        "print(\"\\n🔢 Polynomial Regression (Degree 4) Performance:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
        "\n",
        "# Cross-Validation\n",
        "cv_scores = cross_val_score(poly_model, X, y, cv=5, scoring='r2')\n",
        "cv_preds = cross_val_predict(poly_model, X, y, cv=5)\n",
        "cv_rmse = np.sqrt(mean_squared_error(y, cv_preds))\n",
        "cv_mae = mean_absolute_error(y, cv_preds)\n",
        "cv_r2 = r2_score(y, cv_preds)\n",
        "\n",
        "print(f\"\\n🔁 Cross-Validation (5-Fold):\")\n",
        "print(f\"R² Scores: {cv_scores}\")\n",
        "print(f\"Average R²: {cv_scores.mean():.4f}\")\n",
        "print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
        "print(f\"CV MAE: {cv_mae:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gaussian Process Regression Model ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try RationalQuadratic (can model multiple scales of variation)\n",
        "kernel = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale=1.0, alpha=1.0) + WhiteKernel()\n",
        "\n",
        "# Initialize the Gaussian Process Regressor\n",
        "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, normalize_y=True, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "gpr.fit(X_train, y_train)\n",
        "\n",
        "# Predict mean and standard deviation\n",
        "y_pred_gpr, y_std_gpr = gpr.predict(X_test, return_std=True)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred_gpr)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_gpr)\n",
        "r2 = r2_score(y_test, y_pred_gpr)\n",
        "n, p = X_test.shape\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "print(\"\\n📈 Gaussian Process Regression Performance:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
        "\n",
        "# # Cross-Validation\n",
        "# cv_scores = cross_val_score(gpr, X, y, cv=5, scoring='r2')\n",
        "# cv_preds = cross_val_predict(gpr, X, y, cv=5)\n",
        "# cv_rmse = np.sqrt(mean_squared_error(y, cv_preds))\n",
        "# cv_mae = mean_absolute_error(y, cv_preds)\n",
        "# cv_r2 = r2_score(y, cv_preds)\n",
        "\n",
        "# print(f\"\\n🔁 Cross-Validation (5-Fold):\")\n",
        "# print(f\"R² Scores: {cv_scores}\")\n",
        "# print(f\"Average R²: {cv_scores.mean():.4f}\")\n",
        "# print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
        "# print(f\"CV MAE: {cv_mae:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Comparison ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(24, 10))\n",
        "\n",
        "# 1. Linear Regression\n",
        "plt.subplot(2, 4, 1)\n",
        "plt.scatter(y_test, y_pred_lr, color='blue', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.title(f'Linear Regression\\nR² = {r2_score(y_test, y_pred_lr):.4f}')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(True)\n",
        "\n",
        "# 2. Polynomial Regression (Deg 4)\n",
        "plt.subplot(2, 4, 2)\n",
        "plt.scatter(y_test, y_pred_poly, color='green', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.title(f'Polynomial Regression (Deg 4)\\nR² = {r2_score(y_test, y_pred_poly):.4f}')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(True)\n",
        "\n",
        "# 3. XGBoost\n",
        "plt.subplot(2, 4, 3)\n",
        "plt.scatter(y_test, y_pred_xgb, color='darkorange', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.title(f'XGBoost Regression\\nR² = {r2_score(y_test, y_pred_xgb):.4f}')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(True)\n",
        "\n",
        "# 4. Random Forest\n",
        "plt.subplot(2, 4, 4)\n",
        "plt.scatter(y_test, y_pred_rf, color='purple', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.title(f'Random Forest Regression\\nR² = {r2_score(y_test, y_pred_rf):.4f}')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(True)\n",
        "\n",
        "# 6. Gaussian Process Regression\n",
        "plt.subplot(2, 4, 6)\n",
        "plt.scatter(y_test, y_pred_gpr, color='deepskyblue', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
        "plt.title(f'GPR (RationalQuadratic)\\nR² = {r2_score(y_test, y_pred_gpr):.4f}')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(True)\n",
        "\n",
        "# # 7. Empty slot (optional use later)\n",
        "# plt.subplot(2, 4, 7)\n",
        "# plt.axis('off')\n",
        "\n",
        "plt.suptitle('Model Prediction Comparison (Actual vs Predicted)', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "\n",
        "# Configuration\n",
        "n_models = 10  # number of XGBoost models\n",
        "xgb_models = []\n",
        "xgb_preds = []\n",
        "\n",
        "# Train models on bootstrapped data\n",
        "for i in range(n_models):\n",
        "    # Bootstrap resample the training data\n",
        "    X_boot, y_boot = resample(X_train, y_train, replace=True, random_state=42 + i)\n",
        "    \n",
        "    # Create and train model\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        objective='reg:squarederror',\n",
        "        random_state=42 + i,\n",
        "        verbosity=0\n",
        "    )\n",
        "    model.fit(X_boot, y_boot)\n",
        "    xgb_models.append(model)\n",
        "    \n",
        "    # Predict on test set\n",
        "    pred = model.predict(X_test)\n",
        "    xgb_preds.append(pred)\n",
        "\n",
        "# Stack predictions: shape (n_models, n_samples)\n",
        "xgb_preds = np.array(xgb_preds)\n",
        "\n",
        "# Compute mean and std (uncertainty)\n",
        "xgb_pred_mean = np.mean(xgb_preds, axis=0)\n",
        "xgb_pred_std = np.std(xgb_preds, axis=0)\n",
        "\n",
        "# Now xgb_pred_mean is your final XGBoost prediction\n",
        "# xgb_pred_std is your uncertainty estimate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Predict on test set with all models\n",
        "lin_pred = lr_model.predict(X_test)\n",
        "poly_pred = poly_model.predict(X_test)\n",
        "rf_all_preds = np.array([tree.predict(X_test) for tree in best_rf_model.estimators_])\n",
        "rf_pred = np.mean(rf_all_preds, axis=0)\n",
        "xgb_pred = xgb_pred_mean\n",
        "gpr_pred, gpr_std = gpr.predict(X_test, return_std=True)\n",
        "\n",
        "# Estimate uncertainty\n",
        "lin_uncertainty = np.full_like(lin_pred, np.std(y_train - lr_model.predict(X_train)))\n",
        "poly_uncertainty = np.full_like(poly_pred, np.std(y_train - poly_model.predict(X_train)))\n",
        "rf_uncertainty = np.std(rf_all_preds, axis=0)\n",
        "xgb_uncertainty = xgb_pred_std\n",
        "gpr_uncertainty = gpr_std\n",
        "\n",
        "# Combine into DataFrame\n",
        "meta_df = pd.DataFrame({\n",
        "    'Resistance': X_test.flatten(),\n",
        "    'Lin_Pred': lin_pred,\n",
        "    'Lin_Uncertainty': lin_uncertainty,\n",
        "    'Poly_Pred': poly_pred,\n",
        "    'Poly_Uncertainty': poly_uncertainty,\n",
        "    'RF_Pred': rf_pred,\n",
        "    'RF_Uncertainty': rf_uncertainty,\n",
        "    'XGB_Pred': xgb_pred,\n",
        "    'XGB_Uncertainty': xgb_uncertainty,\n",
        "    'GPR_Pred': gpr_pred,\n",
        "    'GPR_Uncertainty': gpr_uncertainty,\n",
        "    'True_Angle': y_test.values\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "meta_df.to_csv(\"meta_model_input.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (myvenv)",
      "language": "python",
      "name": "myvenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
