{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24540d07-867f-4570-8577-6e3c8cc616cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 1)) (2.2.5)\n",
      "Requirement already satisfied: pandas in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 3)) (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 4)) (1.6.1)\n",
      "Requirement already satisfied: xgboost in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: torch in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from -r req.txt (line 6)) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from pandas->-r req.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from pandas->-r req.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from pandas->-r req.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from matplotlib->-r req.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from scikit-learn->-r req.txt (line 4)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from scikit-learn->-r req.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from scikit-learn->-r req.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from xgboost->-r req.txt (line 5)) (2.26.2)\n",
      "Requirement already satisfied: filelock in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (80.4.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from torch->-r req.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->-r req.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->-r req.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wtl04/coding/gpt/venv/lib/python3.13/site-packages (from jinja2->torch->-r req.txt (line 6)) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r req.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbb947-c3ee-4112-ba20-d9be24a6ebf6",
   "metadata": {},
   "source": [
    "# Creating Neural Network\n",
    "- Input Size: 1 x (2 x m), where m = number of regression models\n",
    "- 4 models: Linear, Poly, XGBoost, Rand Forest, GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e429a52-b356-4872-84ac-cb3e83a5c5c6",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b919e0-390e-476c-a2fb-9fff14b180e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86247d88-510a-45d6-8802-f486fef12149",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6e01d6-e581-413a-836b-19ec553724eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " pred_1        0\n",
      "conf_1        0\n",
      "pred_2        0\n",
      "conf_2        0\n",
      "pred_3        0\n",
      "conf_3        0\n",
      "pred_4        0\n",
      "conf_4        0\n",
      "true_angle    0\n",
      "dtype: int64\n",
      "Data types:\n",
      " pred_1        float64\n",
      "conf_1        float64\n",
      "pred_2        float64\n",
      "conf_2        float64\n",
      "pred_3        float64\n",
      "conf_3        float64\n",
      "pred_4        float64\n",
      "conf_4        float64\n",
      "true_angle    float64\n",
      "dtype: object\n",
      "       pred_1    conf_1      pred_2    conf_2      pred_3    conf_3  \\\n",
      "0  164.444042  2.864122  130.483849  2.462217  113.406224  2.032592   \n",
      "1   89.663341  3.107914   51.598905  2.151310   15.101633  0.735244   \n",
      "2   18.679448  4.158178    6.997265  3.465243   49.060395  4.421956   \n",
      "3   93.175008  2.218811  101.574192  1.015398  179.458291  2.415001   \n",
      "4   65.501893  4.249734   81.768730  3.738013   19.341579  4.307536   \n",
      "\n",
      "       pred_4    conf_4  true_angle  \n",
      "0   54.208624  3.102034   48.684877  \n",
      "1   45.622283  0.834111   34.586665  \n",
      "2   87.298611  1.875094   55.343711  \n",
      "3   62.681515  3.695944   35.873253  \n",
      "4  132.429238  1.452726   57.968464  \n"
     ]
    }
   ],
   "source": [
    "file = \"sim_data_800.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"Data types:\\n\", df.dtypes)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f9bea-ceeb-4708-92f1-46ea3d420947",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae58b68f-486b-41d0-9719-4523b0ba0c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['true_angle'])\n",
    "Y = df['true_angle']\n",
    "\n",
    "# 70/15/15 train val test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.3, random_state=42) # 70% for training\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size = 0.5) # 15% each for val and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2eff2f-678d-4d84-af09-06581c5b88a6",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "- 2 hidden layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cb349e-eb07-4fe9-afe6-de2d93756ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540100b9-75d0-4250-9f27-1466d61a9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size=8, hidden_size=32, output_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534d2e7-87af-42dd-9577-5dd0f683def4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26729686-0d40-4340-8148-cdc3f9e8b6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c650bb4c-be01-4d72-a951-bb6ee0f5dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training dataframes values into tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) # returns y_tensor to size 1\n",
    "\n",
    "# wrap into a dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# create training batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209e0768-a1d5-4c20-b425-92ecb90fef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert validation dataframes values into tensors\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1) # returns y_tensor to size 1\n",
    "\n",
    "# wrap into a dataset\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# create val batches\n",
    "val_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49bcb38a-b7d9-4ef0-a968-e295c9e83b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=1e-4)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ce84246-a7f7-4b5e-a2d5-b5f18ea3125c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 79.7836 | Val Loss: 51.1696 | Patience: 0\n",
      "Epoch 2/30 | Train Loss: 73.6470 | Val Loss: 47.1021 | Patience: 0\n",
      "Epoch 3/30 | Train Loss: 77.4413 | Val Loss: 51.6684 | Patience: 1\n",
      "Epoch 4/30 | Train Loss: 74.6365 | Val Loss: 67.0147 | Patience: 2\n",
      "Epoch 5/30 | Train Loss: 78.4280 | Val Loss: 65.7503 | Patience: 3\n",
      "Epoch 6/30 | Train Loss: 79.1564 | Val Loss: 56.1318 | Patience: 4\n",
      "Epoch 7/30 | Train Loss: 77.9694 | Val Loss: 61.6236 | Patience: 5\n",
      "Epoch 8/30 | Train Loss: 78.9431 | Val Loss: 39.5529 | Patience: 0\n",
      "Epoch 9/30 | Train Loss: 78.2599 | Val Loss: 39.5244 | Patience: 0\n",
      "Epoch 10/30 | Train Loss: 75.2618 | Val Loss: 77.7461 | Patience: 1\n",
      "Epoch 11/30 | Train Loss: 76.6553 | Val Loss: 30.2365 | Patience: 0\n",
      "Epoch 12/30 | Train Loss: 77.5132 | Val Loss: 54.9564 | Patience: 1\n",
      "Epoch 13/30 | Train Loss: 75.2029 | Val Loss: 61.9546 | Patience: 2\n",
      "Epoch 14/30 | Train Loss: 76.7574 | Val Loss: 67.0529 | Patience: 3\n",
      "Epoch 15/30 | Train Loss: 77.4838 | Val Loss: 28.9979 | Patience: 0\n",
      "Epoch 16/30 | Train Loss: 78.2571 | Val Loss: 48.4449 | Patience: 1\n",
      "Epoch 17/30 | Train Loss: 76.8013 | Val Loss: 47.8428 | Patience: 2\n",
      "Epoch 18/30 | Train Loss: 75.1103 | Val Loss: 58.5204 | Patience: 3\n",
      "Epoch 19/30 | Train Loss: 79.7478 | Val Loss: 48.0998 | Patience: 4\n",
      "Epoch 20/30 | Train Loss: 75.6219 | Val Loss: 69.2386 | Patience: 5\n",
      "Epoch 21/30 | Train Loss: 76.7055 | Val Loss: 62.7001 | Patience: 6\n",
      "Epoch 22/30 | Train Loss: 76.3453 | Val Loss: 46.4152 | Patience: 7\n",
      "Epoch 23/30 | Train Loss: 73.3650 | Val Loss: 55.3483 | Patience: 8\n",
      "Epoch 24/30 | Train Loss: 75.4708 | Val Loss: 38.0356 | Patience: 9\n",
      "Epoch 25/30 | Train Loss: 74.9797 | Val Loss: 54.9234 | Patience: 10\n",
      "Epoch 26/30 | Train Loss: 73.9976 | Val Loss: 25.8195 | Patience: 0\n",
      "Epoch 27/30 | Train Loss: 77.2069 | Val Loss: 52.3866 | Patience: 1\n",
      "Epoch 28/30 | Train Loss: 72.4960 | Val Loss: 32.3251 | Patience: 2\n",
      "Epoch 29/30 | Train Loss: 75.3622 | Val Loss: 32.7071 | Patience: 3\n",
      "Epoch 30/30 | Train Loss: 75.8704 | Val Loss: 45.5507 | Patience: 4\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "patience_limit = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # move data to GPU or CPU\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # forward step\n",
    "        outputs = model(X_batch)\n",
    "        loss = loss_func(outputs, y_batch)\n",
    "\n",
    "        # backward step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate running loss\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    # total training loss\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "    # validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            # move data to GPU or CPU\n",
    "            X_val_batch = X_batch.to(device)\n",
    "            y_val_batch = y_batch.to(device)\n",
    "\n",
    "            # forward step\n",
    "            val_outputs = model(X_val_batch)\n",
    "            loss = loss_func(val_outputs, y_val_batch)\n",
    "\n",
    "            # calculate running loss \n",
    "            val_loss += loss.item() * X_val_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "\n",
    "    # adding early stopping to prevent overfitting            \n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss \n",
    "        best_model_state = model.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience_limit:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Patience: {patience_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc14e6-7141-4333-8c95-3c09a6fc948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model after training\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f77e7a-1184-4797-9389-3e51402cca5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc638e1-6743-46fb-94ea-582a6fa86f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
